{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f78603d9",
   "metadata": {},
   "source": [
    "## Este es un ejemplo de uso de la clase BCIDataset para el TP3\n",
    "\n",
    "El video donde es trabajado se encuentra en https://youtu.be/b0Z7m6-BrqY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eb7d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import utils\n",
    "from typing import Callable\n",
    "import scipy\n",
    "import scipy.signal as sgn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac2eb846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_fft_features(signal_matrix):\n",
    "    N = signal_matrix.shape[1]\n",
    "    dt = 1/200\n",
    "    T = N*dt\n",
    "    sf = 200\n",
    "    Q = 30\n",
    "    f_notch = 50\n",
    "    b_notch, a_notch = sgn.iirnotch(w0=f_notch, Q=Q, fs=sf)\n",
    "    sig_notch = sgn.filtfilt(b_notch, a_notch, signal_matrix, axis=1)\n",
    "\n",
    "    #Ahora creamos el filtro pasabanda Butterworth\n",
    "    f_nq = sf/2\n",
    "    f_low = 5\n",
    "    f_high = 40\n",
    "    order = 4\n",
    "    b_band, a_band = sgn.iirfilter(\n",
    "        N=order, Wn=[f_low/f_nq, f_high/f_nq], btype=\"bandpass\", ftype=\"butter\"\n",
    "    )\n",
    "    sig_filt = sgn.filtfilt(b_band, a_band, sig_notch, axis=1)\n",
    "\n",
    "    fft = np.fft.rfft(sig_filt)\n",
    "    Sxx = np.real(((2*dt**2)/T)*fft*fft.conj())\n",
    "    return Sxx\n",
    "\n",
    "\n",
    "def naif_fft_features(signal_matrix):\n",
    "    N = signal_matrix.shape[1]\n",
    "    dt = 1/200\n",
    "    T = N*dt\n",
    "    fft = np.fft.rfft(signal_matrix)\n",
    "    Sxx = np.real(((2*dt**2)/T)*fft*fft.conj())\n",
    "    return Sxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54375c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCIDataset():\n",
    "    def __init__(\n",
    "        self, \n",
    "        csvs_path, \n",
    "        subject: str = 'all', \n",
    "        session: str = 'all',\n",
    "        channel: str = 'all', \n",
    "        overlapping_fraction: float = 1/3, \n",
    "        window_size: int = 900,\n",
    "        feature_extractor: Callable = naif_fft_features\n",
    "    ):\n",
    "        '''\n",
    "        Object containing all examples from a time series from the dataset.\n",
    "        Args:\n",
    "            csvs_path (str): path al directorio donde estan los csv de los datos\n",
    "            subject (str): sujeto a estudiar.\n",
    "                Si se indica 'all' el dataset final generado tendrá ejemplos de todos los sujetos\n",
    "            session (str): sesión a estudiar del sujeto seleccionado.\n",
    "                si se indica 'all'  el dataset final generado tendrá ejemplos de todas las sesiones\n",
    "            channel (str): 'ch0', 'ch1', 'ch2', 'ch3'. Si se indica 'all', los ejemplos serán la\n",
    "                concatenación de los 4 canales.\n",
    "            overlapping_fraction (float): porcentaje de desplazamiento de la \"ventana\" que hace el ejemplo\n",
    "            window_size (int): tamaño de la ventana de tiempo que hace a un ejemplo (en muestras).\n",
    "            feature_extractor (func): Función de extracción de features, le ingresa un arreglo\n",
    "                (ejemplos en las filas, muestras en las columnas) y devuelve un arreglo (ejemplos en\n",
    "                las filas y features en las columnas)\n",
    "        '''\n",
    "        self.csvs_path = Path(csvs_path)\n",
    "        self.channel = channel\n",
    "        self.parts = int(1 / overlapping_fraction)\n",
    "        self.fraction = 1 / self.parts\n",
    "        self.ws = window_size\n",
    "        self.subject = subject\n",
    "        self.session = session\n",
    "        self.channels = ['ch0','ch1','ch2','ch3']\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.complete_dataset = utils.read_all_datasets(self.csvs_path)\n",
    "        \n",
    "        self.complete_examples_signal, self.complete_examples_features, \\\n",
    "        self.complete_labels, self.complete_metadata = \\\n",
    "            self.generate_examples()\n",
    "        \n",
    "    def generate_examples(self):\n",
    "        # For each session generate the signal examples,\n",
    "        # the feature extraction examples and labels arrays\n",
    "        complete_examples_signal, complete_examples_features = [], []\n",
    "        complete_labels, complete_metadata = [], []\n",
    "        \n",
    "        for subject in self.complete_dataset.subject.unique():\n",
    "            # Just load the selected subject\n",
    "            if self.subject != 'all' and subject != self.subject:\n",
    "                continue\n",
    "            sessions = \\\n",
    "                self.complete_dataset.loc[self.complete_dataset.subject==subject].session.unique()\n",
    "            for session in sessions:\n",
    "                # Just load the selected session\n",
    "                if self.session != 'all' and session != self.session:\n",
    "                    continue\n",
    "                \n",
    "                print(f'Processing subject: {subject} - session: {session}...')\n",
    "                \n",
    "                # Generate a subset of the dataset only with the desired rows\n",
    "                selection = self.complete_dataset.loc[\n",
    "                    (self.complete_dataset.subject==subject) &\n",
    "                    (self.complete_dataset.session==session)\n",
    "                ]\n",
    "                \n",
    "                # Standarize length of the array to a multiple to window size\n",
    "                labels = selection.label.values\n",
    "                n_rows = labels.shape[0] // self.ws\n",
    "                labels = labels[: n_rows * self.ws]\n",
    "\n",
    "                # Generate examples from the signal\n",
    "                n_examples = n_rows * self.parts - (self.parts - 1)\n",
    "                examples = np.empty((n_examples, self.ws))\n",
    "                most_frec_labels = np.empty((n_examples, self.ws))\n",
    "                times = np.empty((n_examples, self.ws))\n",
    "                \n",
    "                concat_ch_examples_signal, concat_ch_examples_features = [], []\n",
    "\n",
    "                for k, ch in enumerate(self.channels):\n",
    "                    # Use the four channels or just one\n",
    "                    if self.channel != 'all' and self.channel != ch:\n",
    "                        continue\n",
    "                    \n",
    "                    # Standarize length of the signal to a multiple to window size\n",
    "                    signal = selection[ch].values\n",
    "                    signal = signal[: n_rows * self.ws]\n",
    "                    time = selection.time.values\n",
    "                    time = time[: n_rows * self.ws]\n",
    "\n",
    "                    # Increase the number of examples by overlapping the windows\n",
    "                    for part in range(self.parts):\n",
    "                        \n",
    "                        # Find the place in the output array for each example\n",
    "                        position = np.arange(part, n_examples, self.parts)\n",
    "                        #position = position if part == 0 else position[:-part]\n",
    "\n",
    "                        # Crop the signal according to the window size and overlap\n",
    "                        start = int(self.ws / self.parts) * part\n",
    "                        end = -int(self.ws - (self.ws / self.parts) * part)\n",
    "                        end = end if part!=0 else signal.shape[0]\n",
    "                        subset_signal = signal[start:end]\n",
    "                        subset_labels = labels[start:end]\n",
    "                        subset_times = time[start:end]\n",
    "\n",
    "                        # Generate the examples\n",
    "                        n_rows_ = int(subset_signal.shape[0]/self.ws)\n",
    "                        examples[position, :] = subset_signal.reshape((n_rows_, self.ws))\n",
    "                        most_frec_labels[position, :] = subset_labels.reshape((n_rows_, self.ws))\n",
    "                        times[position, :] = subset_times.reshape((n_rows_, self.ws))\n",
    "                    \n",
    "                    # Obtain most frequent label\n",
    "                    labels_ = scipy.stats.mode(most_frec_labels, axis=1).mode\n",
    "                    labels_temp = scipy.stats.mode(most_frec_labels, axis=1).count\n",
    "                    pureness = labels_temp == self.ws\n",
    "                    # Get first and last time of the window\n",
    "                    times_ = np.asarray([np.min(times, axis=1), np.max(times, axis=1)]).T\n",
    "                    # Extract features\n",
    "                    features = self.feature_extractor(examples)\n",
    "\n",
    "                    concat_ch_examples_signal.append(examples.copy())\n",
    "                    concat_ch_examples_features.append(features)\n",
    "\n",
    "                concat_ch_examples_signal = np.concatenate(concat_ch_examples_signal, axis=1)\n",
    "                concat_ch_examples_features = np.concatenate(concat_ch_examples_features, axis=1)\n",
    "\n",
    "                complete_examples_signal.append(concat_ch_examples_signal)\n",
    "                complete_examples_features.append(concat_ch_examples_features)\n",
    "                complete_labels.append(labels_)\n",
    "                lt = len(times_)\n",
    "                metadata_ = np.concatenate(\n",
    "                    [pureness, times_, np.repeat(subject, lt)[:,None], np.repeat(session, lt)[:,None]],\n",
    "                    axis=1\n",
    "                )\n",
    "                complete_metadata.append(metadata_)\n",
    "\n",
    "        complete_examples_signal = np.concatenate(complete_examples_signal)\n",
    "        complete_examples_features = np.concatenate(complete_examples_features)\n",
    "        complete_labels = np.concatenate(complete_labels)\n",
    "        complete_metadata = np.concatenate(complete_metadata)\n",
    "        \n",
    "        return complete_examples_signal, complete_examples_features, complete_labels, complete_metadata\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.complete_examples_signal.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'signal': self.complete_examples_signal[idx,:],\n",
    "            'features': self.complete_examples_features[idx,:],\n",
    "            'label': self.complete_labels[idx,:],\n",
    "            'metadata': self.complete_metadata[idx,:]\n",
    "        }\n",
    "\n",
    "    def get_X_signal(self):\n",
    "        return self.complete_examples_signal\n",
    "\n",
    "    def get_X_features(self):\n",
    "        return self.complete_examples_features\n",
    "\n",
    "    def get_Y(self):\n",
    "        return self.complete_labels\n",
    "\n",
    "    def get_metadata(self):\n",
    "        return self.complete_metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c1278c",
   "metadata": {},
   "source": [
    "Para levantar los datasets desde txt o csv:\n",
    "- Este notebook, o el notebook que usen que tenga la clase arriba definida, tiene que estar en el mismo directorio que el archivo utils.py, que tiene algunas funciones usadas en los métodos de la clase.\n",
    "- Descarguen el .zip de la base de datos de nuevo y extraiganlos a un directorio llamado <path al repo en su máquina>/MentoriaBCI/Database/\n",
    "- Definan el csvs_path acorde al directorio anterior:\n",
    "    - csvs_path = '<PATH AL REPO>/MetoriaBCI/Database' ej: '/home/joaquin/Desktop/MentoriaDiploDatos/MetoriaBCI/Database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5b3804",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs_path = '../Database'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0510a17",
   "metadata": {},
   "source": [
    "### A) b) Estudiar cómo varía el número de ejemplos en el dataset y la dimensión de cada dato según la variación de la ventana de tiempo seleccionada y el criterio de solapamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f025569b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: AA - session: 0...\n",
      "Dimensiones de ventanas de dataset1: (151, 3600)\n",
      "Dimensiones de features de dataset1: (151, 1804)\n",
      "Processing subject: AA - session: 0...\n",
      "Dimensiones de ventanas de dataset2: (304, 1800)\n",
      "Dimensiones de features de dataset2: (304, 904)\n",
      "Processing subject: AA - session: 0...\n",
      "Dimensiones de ventanas de dataset3: (201, 3600)\n",
      "Dimensiones de features de dataset3: (201, 1804)\n",
      "Processing subject: AA - session: 0...\n",
      "Dimensiones de ventanas de dataset4: (361, 7200)\n",
      "Dimensiones de features de dataset4: (361, 3604)\n"
     ]
    }
   ],
   "source": [
    "dataset1 = BCIDataset(csvs_path, subject = \"AA\", session = \"0\")\n",
    "\n",
    "print('Dimensiones de ventanas de dataset1:', dataset1.get_X_signal().shape)\n",
    "print('Dimensiones de features de dataset1:', dataset1.get_X_features().shape)\n",
    "\n",
    "dataset2 = BCIDataset(csvs_path, subject = \"AA\", session = \"0\", window_size = 450)\n",
    "\n",
    "print('Dimensiones de ventanas de dataset2:', dataset2.get_X_signal().shape)\n",
    "print('Dimensiones de features de dataset2:', dataset2.get_X_features().shape)\n",
    "\n",
    "dataset3 = BCIDataset(csvs_path, subject = \"AA\", session = \"0\", overlapping_fraction=1/4)\n",
    "\n",
    "print('Dimensiones de ventanas de dataset3:', dataset3.get_X_signal().shape)\n",
    "print('Dimensiones de features de dataset3:', dataset3.get_X_features().shape)\n",
    "\n",
    "dataset4 = BCIDataset(csvs_path, subject = \"AA\", session = \"0\", window_size=1800, overlapping_fraction=1/15)\n",
    "\n",
    "print('Dimensiones de ventanas de dataset4:', dataset4.get_X_signal().shape)\n",
    "print('Dimensiones de features de dataset4:', dataset4.get_X_features().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117712cd",
   "metadata": {},
   "source": [
    "### B) c) En adición a la serie temporal cruda -”complete_examples_signal” de BCIDataset- (concatenada o no a lo largo de los canales, según su elección), defina una estrategia de extracción de atributos en el dominio de tiempo que opere sobre la serie cruda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6f045fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: AA - session: 0...\n",
      "Dimensiones de ventanas de dataset5: (151, 3600)\n",
      "Dimensiones de features de dataset5: (151, 1804)\n",
      "Processing subject: AA - session: 0...\n",
      "primer fila de dataset6: [-1.86 10.77 87.61 83.04  8.07]\n",
      "\n",
      "primer fila de dataset6: [398.14 410.77 487.61 483.04 408.07]\n",
      "Processing subject: AA - session: 0...\n",
      "Dimensiones de ventanas de dataset7: (151, 3600)\n",
      "Dimensiones de features de dataset7: (151, 8)\n",
      "primer fila de dataset7: [-1.86 10.77 87.61 83.04  8.07]\n",
      "\n",
      "primer fila de dataset7: [ 51.51517778   0.          32.19205556   0.          54.17357778\n",
      "   0.         -33.06123333   0.        ]\n"
     ]
    }
   ],
   "source": [
    "dataset5 = BCIDataset(csvs_path, subject = \"AA\", session = \"0\", feature_extractor = filtered_fft_features)\n",
    "\n",
    "print('Dimensiones de ventanas de dataset5:', dataset5.get_X_signal().shape)\n",
    "print('Dimensiones de features de dataset5:', dataset5.get_X_features().shape)\n",
    "\n",
    "def sum400(signal_matrix):\n",
    "    return signal_matrix + 400\n",
    "\n",
    "dataset6 = BCIDataset(csvs_path, subject = \"AA\", session = \"0\", feature_extractor = sum400)\n",
    "\n",
    "print('primer fila de dataset6:', dataset6.get_X_signal()[0,:5])\n",
    "print()\n",
    "print('primer fila de dataset6:', dataset6.get_X_features()[0,:5])\n",
    "\n",
    "def mean_and_newcolumn(signal_matrix):\n",
    "    means = signal_matrix.mean(axis=1)[:, np.newaxis]\n",
    "    means = np.hstack([means, np.zeros(means.shape)])\n",
    "    return means\n",
    "\n",
    "dataset7 = BCIDataset(csvs_path, subject = \"AA\", session = \"0\", feature_extractor = mean_and_newcolumn)\n",
    "\n",
    "print('Dimensiones de ventanas de dataset7:', dataset7.get_X_signal().shape)\n",
    "print('Dimensiones de features de dataset7:', dataset7.get_X_features().shape)\n",
    "\n",
    "print('primer fila de dataset7:', dataset7.get_X_signal()[0,:5])\n",
    "print()\n",
    "print('primer fila de dataset7:', dataset7.get_X_features()[0,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce1208",
   "metadata": {},
   "source": [
    "### C) a) Usando BCIDataset, con el extractor de features básico de fft, o el procesador de datos que desee, genere el dataset de ejemplos utilizado como atributos el espectrograma de potencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "67a9f284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject: AA - session: 0...\n",
      "Dimensiones de ventanas de dataset8: (151, 3600)\n",
      "Dimensiones de features de dataset8: (151, 8)\n",
      "primer fila de dataset1: [4.19762044 8.4187574  0.49655619 7.44543761 1.19898483 1.23263297\n",
      " 5.16148451 0.72575445 1.42149166 3.04204042 2.70376405 1.31435521\n",
      " 1.87550838 1.12606688 0.01666563 1.0739737  1.84534265 0.92770828\n",
      " 0.04823913 0.70581164 0.29577067 3.6070825  3.41152378 2.39843848\n",
      " 0.27087759 0.4858284  1.57678644 0.5845709  2.5801894  0.23302799]\n",
      "\n",
      "primer fila de dataset8: [5.16148451 0.27087759 1.60691267 0.6609744  4.73681774 0.52951126\n",
      " 2.80698654 0.42239365]\n"
     ]
    }
   ],
   "source": [
    "pos_125 = 56 #cambiaria si cambia window_size\n",
    "pos_165 = 74 #cambiaria si cambia window_size\n",
    "window_size = 900\n",
    "\n",
    "def super_fft_features(signal_matrix):\n",
    "    N = signal_matrix.shape[1]\n",
    "    dt = 1/200\n",
    "    T = N*dt\n",
    "    fft = np.fft.rfft(signal_matrix)\n",
    "    Sxx = np.real(((2*dt**2)/T)*fft*fft.conj())\n",
    "    \n",
    "    interest_freq_125 = Sxx[:, pos_125:pos_125+1]\n",
    "    interest_freq_165 = Sxx[:, pos_165:pos_165+1]\n",
    "    interest_freq = np.hstack([interest_freq_125, interest_freq_165])\n",
    "    \n",
    "    return interest_freq\n",
    "\n",
    "dataset8 = BCIDataset(csvs_path, subject = \"AA\", session = \"0\", feature_extractor = super_fft_features)\n",
    "\n",
    "print('Dimensiones de ventanas de dataset8:', dataset8.get_X_signal().shape)\n",
    "print('Dimensiones de features de dataset8:', dataset8.get_X_features().shape)\n",
    "\n",
    "print('primer fila de dataset1:', dataset1.get_X_features()[0,50:80])\n",
    "print()\n",
    "print('primer fila de dataset8:', dataset8.get_X_features()[0,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
