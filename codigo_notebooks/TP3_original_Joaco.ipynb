{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b68bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import utils\n",
    "from typing import Callable\n",
    "import scipy\n",
    "import scipy.signal as sgn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e69cdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtered_fft_features(signal_matrix):\n",
    "    N = signal_matrix.shape[1]\n",
    "    dt = 1/200\n",
    "    T = N*dt\n",
    "    sf = 200\n",
    "    Q = 30\n",
    "    f_notch = 50\n",
    "    b_notch, a_notch = sgn.iirnotch(w0=f_notch, Q=Q, fs=sf)\n",
    "    sig_notch = sgn.filtfilt(b_notch, a_notch, signal_matrix, axis=1)\n",
    "\n",
    "    #Ahora creamos el filtro pasabanda Butterworth\n",
    "    f_nq = sf/2\n",
    "    f_low = 5\n",
    "    f_high = 40\n",
    "    order = 4\n",
    "    b_band, a_band = sgn.iirfilter(\n",
    "        N=order, Wn=[f_low/f_nq, f_high/f_nq], btype=\"bandpass\", ftype=\"butter\"\n",
    "    )\n",
    "    sig_filt = sgn.filtfilt(b_band, a_band, sig_notch, axis=1)\n",
    "\n",
    "    fft = np.fft.rfft(sig_filt)\n",
    "    Sxx = np.real(((2*dt**2)/T)*fft*fft.conj())\n",
    "    return Sxx\n",
    "\n",
    "\n",
    "def naif_fft_features(signal_matrix):\n",
    "    N = signal_matrix.shape[1]\n",
    "    dt = 1/200\n",
    "    T = N*dt\n",
    "    fft = np.fft.rfft(signal_matrix)\n",
    "    Sxx = np.real(((2*dt**2)/T)*fft*fft.conj())\n",
    "    return Sxx\n",
    "\n",
    "def calc_statistics(s):\n",
    "    maxim = np.max(s, axis = 1)[:, np.newaxis]\n",
    "    minim = np.min(s, axis = 1)[:, np.newaxis]\n",
    "    mean = np.mean(s, axis = 1)[:, np.newaxis]\n",
    "    \n",
    "    mode = scipy.stats.mode(s, axis = 1)[0]\n",
    "    \n",
    "    return np.concatenate([maxim, minim, mean, mode], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90750901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BCIDataset():\n",
    "    def __init__(\n",
    "        self, \n",
    "        csvs_path, \n",
    "        subject: str = 'all', \n",
    "        session: str = 'all',\n",
    "        channel: str = 'all', \n",
    "        overlapping_fraction: float = 1/3, \n",
    "        window_size: int = 900,\n",
    "        feature_extractor: Callable = naif_fft_features\n",
    "    ):\n",
    "        '''\n",
    "        Object containing all examples from a time series from the dataset.\n",
    "        Args:\n",
    "            csvs_path (str): path al directorio donde estan los csv de los datos\n",
    "            subject (str): sujeto a estudiar.\n",
    "                Si se indica 'all' el dataset final generado tendrá ejemplos de todos los sujetos\n",
    "            session (str): sesión a estudiar del sujeto seleccionado.\n",
    "                si se indica 'all'  el dataset final generado tendrá ejemplos de todas las sesiones\n",
    "            channel (str): 'ch0', 'ch1', 'ch2', 'ch3'. Si se indica 'all', los ejemplos serán la\n",
    "                concatenación de los 4 canales.\n",
    "            overlapping_fraction (float): porcentaje de desplazamiento de la \"ventana\" que hace el ejemplo\n",
    "            window_size (int): tamaño de la ventana de tiempo que hace a un ejemplo (en muestras).\n",
    "            feature_extractor (func): Función de extracción de features, le ingresa un arreglo\n",
    "                (ejemplos en las filas, muestras en las columnas) y devuelve un arreglo (ejemplos en\n",
    "                las filas y features en las columnas)\n",
    "        '''\n",
    "        self.csvs_path = Path(csvs_path)\n",
    "        self.channel = channel\n",
    "        self.parts = int(1 / overlapping_fraction)\n",
    "        self.fraction = 1 / self.parts\n",
    "        self.ws = window_size\n",
    "        self.subject = subject\n",
    "        self.session = session\n",
    "        self.channels = ['ch0','ch1','ch2','ch3']\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.complete_dataset = utils.read_all_datasets(self.csvs_path)\n",
    "        \n",
    "        self.complete_examples_signal, self.complete_examples_features, \\\n",
    "        self.complete_labels, self.complete_metadata = \\\n",
    "            self.generate_examples()\n",
    "        \n",
    "    def generate_examples(self):\n",
    "        # For each session generate the signal examples,\n",
    "        # the feature extraction examples and labels arrays\n",
    "        complete_examples_signal, complete_examples_features = [], []\n",
    "        complete_labels, complete_metadata = [], []\n",
    "        \n",
    "        for subject in self.complete_dataset.subject.unique():\n",
    "            # Just load the selected subject\n",
    "            if self.subject != 'all' and subject != self.subject:\n",
    "                continue\n",
    "            sessions = \\\n",
    "                self.complete_dataset.loc[self.complete_dataset.subject==subject].session.unique()\n",
    "            for session in sessions:\n",
    "                # Just load the selected session\n",
    "                if self.session != 'all' and session != self.session:\n",
    "                    continue\n",
    "                \n",
    "                print(f'Processing subject: {subject} - session: {session}...')\n",
    "                \n",
    "                # Generate a subset of the dataset only with the desired rows\n",
    "                selection = self.complete_dataset.loc[\n",
    "                    (self.complete_dataset.subject==subject) &\n",
    "                    (self.complete_dataset.session==session)\n",
    "                ]\n",
    "                \n",
    "                # Standarize length of the array to a multiple to window size\n",
    "                labels = selection.label.values\n",
    "                n_rows = labels.shape[0] // self.ws\n",
    "                labels = labels[: n_rows * self.ws]\n",
    "\n",
    "                # Generate examples from the signal\n",
    "                n_examples = n_rows * self.parts - (self.parts - 1)\n",
    "                examples = np.empty((n_examples, self.ws))\n",
    "                most_frec_labels = np.empty((n_examples, self.ws))\n",
    "                times = np.empty((n_examples, self.ws))\n",
    "                \n",
    "                concat_ch_examples_signal, concat_ch_examples_features = [], []\n",
    "\n",
    "                for k, ch in enumerate(self.channels):\n",
    "                    # Use the four channels or just one\n",
    "                    if self.channel != 'all' and self.channel != ch:\n",
    "                        continue\n",
    "                    \n",
    "                    # Standarize length of the signal to a multiple to window size\n",
    "                    signal = selection[ch].values\n",
    "                    signal = signal[: n_rows * self.ws]\n",
    "                    time = selection.time.values\n",
    "                    time = time[: n_rows * self.ws]\n",
    "\n",
    "                    # Increase the number of examples by overlapping the windows\n",
    "                    for part in range(self.parts):\n",
    "                        \n",
    "                        # Find the place in the output array for each example\n",
    "                        position = np.arange(part, n_examples, self.parts)\n",
    "                        #position = position if part == 0 else position[:-part]\n",
    "\n",
    "                        # Crop the signal according to the window size and overlap\n",
    "                        start = int(self.ws / self.parts) * part\n",
    "                        end = -int(self.ws - (self.ws / self.parts) * part)\n",
    "                        end = end if part!=0 else signal.shape[0]\n",
    "                        subset_signal = signal[start:end]\n",
    "                        subset_labels = labels[start:end]\n",
    "                        subset_times = time[start:end]\n",
    "\n",
    "                        # Generate the examples\n",
    "                        n_rows_ = int(subset_signal.shape[0]/self.ws)\n",
    "                        examples[position, :] = subset_signal.reshape((n_rows_, self.ws))\n",
    "                        most_frec_labels[position, :] = subset_labels.reshape((n_rows_, self.ws))\n",
    "                        times[position, :] = subset_times.reshape((n_rows_, self.ws))\n",
    "                    \n",
    "                    # Obtain most frequent label\n",
    "                    labels_ = scipy.stats.mode(most_frec_labels, axis=1).mode\n",
    "                    labels_temp = scipy.stats.mode(most_frec_labels, axis=1).count\n",
    "                    pureness = labels_temp == self.ws\n",
    "                    # Get first and last time of the window\n",
    "                    times_ = np.asarray([np.min(times, axis=1), np.max(times, axis=1)]).T\n",
    "                    # Extract features\n",
    "                    features = self.feature_extractor(examples)\n",
    "\n",
    "                    concat_ch_examples_signal.append(examples.copy())\n",
    "                    concat_ch_examples_features.append(features)\n",
    "\n",
    "                concat_ch_examples_signal = np.concatenate(concat_ch_examples_signal, axis=1)\n",
    "                concat_ch_examples_features = np.concatenate(concat_ch_examples_features, axis=1)\n",
    "\n",
    "                complete_examples_signal.append(concat_ch_examples_signal)\n",
    "                complete_examples_features.append(concat_ch_examples_features)\n",
    "                complete_labels.append(labels_)\n",
    "                lt = len(times_)\n",
    "                metadata_ = np.concatenate(\n",
    "                    [pureness, times_, np.repeat(subject, lt)[:,None], np.repeat(session, lt)[:,None]],\n",
    "                    axis=1\n",
    "                )\n",
    "                complete_metadata.append(metadata_)\n",
    "\n",
    "        complete_examples_signal = np.concatenate(complete_examples_signal)\n",
    "        complete_examples_features = np.concatenate(complete_examples_features)\n",
    "        complete_labels = np.concatenate(complete_labels)\n",
    "        complete_metadata = np.concatenate(complete_metadata)\n",
    "        \n",
    "        return complete_examples_signal, complete_examples_features, complete_labels, complete_metadata\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.complete_examples_signal.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'signal': self.complete_examples_signal[idx,:],\n",
    "            'features': self.complete_examples_features[idx,:],\n",
    "            'label': self.complete_labels[idx,:],\n",
    "            'metadata': self.complete_metadata[idx,:]\n",
    "        }\n",
    "\n",
    "    def get_X_signal(self):\n",
    "        return self.complete_examples_signal\n",
    "\n",
    "    def get_X_features(self):\n",
    "        return self.complete_examples_features\n",
    "\n",
    "    def get_Y(self):\n",
    "        return self.complete_labels\n",
    "\n",
    "    def get_metadata(self):\n",
    "        return self.complete_metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd7e288",
   "metadata": {},
   "source": [
    "Para levantar los datasets desde txt o csv:\n",
    "- Este notebook, o el notebook que usen que tenga la clase arriba definida, tiene que estar en el mismo directorio que el archivo utils.py, que tiene algunas funciones usadas en los métodos de la clase.\n",
    "- Descarguen el .zip de la base de datos de nuevo y extraiganlos a un directorio llamado <path al repo en su máquina>/MentoriaBCI/Database/\n",
    "- Definan el csvs_path acorde al directorio anterior:\n",
    "    - csvs_path = '<PATH AL REPO>/MetoriaBCI/Database' ej: '/home/joaquin/Desktop/MentoriaDiploDatos/MetoriaBCI/Database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csvs_path = '/home/joaquin/Desktop/MentoriaDiploDatos/MetoriaBCI/Database'\n",
    "# dataset = BCIDataset(csvs_path, subject='AA', session='0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fd53ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata = pd.DataFrame(dataset.complete_metadata, columns = ['pureness', 't_start', 't_end', 'subject', 'session'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff3a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata.pureness.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa42d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(15,4))\n",
    "# plt.plot(dataset.complete_examples_features[2,:])\n",
    "# plt.ylim([0,6])\n",
    "# # plt.xlim([8,40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceac028a",
   "metadata": {},
   "source": [
    "# Recorrido por el código BCIDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bfd929",
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs_path = '../data'\n",
    "dataset_con_max = BCIDataset(\n",
    "    csvs_path,\n",
    "    subject='all',\n",
    "    session='all',\n",
    "    channel='all', \n",
    "    overlapping_fraction=1/8,\n",
    "    window_size=512,\n",
    "    feature_extractor=calc_statistics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536790d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_con_max.complete_dataset.loc[dataset_con_max.complete_dataset.sub_label == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee8908",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_con_max.complete_examples_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b185b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(dataset_con_max.complete_labels, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a970ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vec1, vec2 = dataset_con_max.complete_examples_signal[10, 0:512], dataset_con_max.complete_examples_signal[10, 512:1024]\n",
    "all([v1==v2 for v1,v2 in zip(vec1,vec2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ba61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(dataset.complete_examples_features[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3170a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.csvs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8471446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataframe(data, feature_metrics, chan_list = [1,2,3,4])\n",
    "    metrics_final = []\n",
    "    for ch in chan_list:\n",
    "        for met in feature_metrics:\n",
    "            metrics_final.append(met + \"ch\" + str(ch))\n",
    "            \n",
    "    if len(metrics_final) != data.shape[1]:\n",
    "        print(\"The sizes are wrong, the metrics have\" + str(len(metrics_final)) + \"and the data has \"+ str(data.shape[1]))\n",
    "        return None\n",
    "    \n",
    "    return pd.DataFrame(data, columns=metrics_final)\n",
    "        \n",
    "    \n",
    "dataset1max = jvnkdjnvadkn\n",
    "\n",
    "dataset1_df = generate_dataframe(dataset1max, [\"f0\", \"f1\", \"f2\"], [1,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db05fee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
